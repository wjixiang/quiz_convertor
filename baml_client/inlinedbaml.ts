/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "clients.baml": "client<llm> GLM4Plus {\n  provider openai-generic\n  options {\n    model \"glm-4-plus\"\n    api_key env.GLM_API_KEY\n    base_url \"https://open.bigmodel.cn/api/paas/v4\"\n    retry_policy GLMRetry\n  }\n}\n\nclient<llm> QiniuDeepseekV3 {\n  provider openai-generic\n  options {\n    model \"deepseek-v3\"\n    api_key env.QINIU_DEEPSEEK_FREE_API_KEY\n    base_url \"https://api.qnaigc.com/v1\"\n  }\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.90.2\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "quiz.baml": "// Quiz conversion using LLM\nclass QuestionAnswerPair {\n  question string\n  answer string\n}\n\nclass QuestionAnswerSlice {\n  question_range int[]\n  /// The correct answer(s) as option letters:\n  /// - Single choice: \"A\", \"B\", etc.\n  /// - Multiple choice: \"AB\", \"ACD\", etc. (any combination of A-E)\n  answer string\n}\n\nclass ContentSlice {\n  start int\n  end int\n}\n\nclass QuizOptions {\n  oid \"A\"|\"B\"|\"C\"|\"D\"|\"E\"\n  text string\n}\n\nclass QuizAnalysis {\n  point string?\n  discuss string?\n  ai_analysis string?\n  link string[]\n}\n\nclass BasicQuiz {\n  type \"single\" | \"multiple\"\n  question string\n  options string[]\n  answer string\n}\n\nclass A1Quiz {\n  type \"A1\"\n  class string\n  unit string\n  tags string[]\n  question string\n  options QuizOptions[]\n  answer \"A\"|\"B\"|\"C\"|\"D\"|\"E\"\n  analysis QuizAnalysis\n  source string\n}\n\nclass A2Quiz {\n  type \"A2\"\n  class string\n  unit string\n  tags string[]\n  question string\n  options QuizOptions[]\n  answer \"A\"|\"B\"|\"C\"|\"D\"|\"E\"\n  analysis QuizAnalysis\n  source string\n}\n\nfunction SplitQuestions(questions_text: string) -> string[] {\n  client GLM4Plus\n  prompt #\"\n    {{_.role(\"user\")}}\n    Split the following text into individual questions. The text may contain:\n    - Numbered questions (1., 2., etc)\n    - Bullet points\n    - Blank lines between questions\n    - Other separators\n    \n    Text to split:\n    {{ questions_text }}\n    \n    Return a JSON array where each element is a complete question text.\n    Only return the array, nothing else.\n  \"#\n}\n\nfunction ConvertToA1(question: string, answer: string) -> A1Quiz {\n  client GLM4Plus\n  prompt #\"\n    {{_.role(\"user\")}}\n    Convert the following question and answer into a structured multiple choice quiz (A1 type):\n    \n    Question:\n    {{ question }}\n    \n    Answer:\n    {{ answer }}\n    \n    Requirements:\n    - Include analysis with key points and discussion\n    - Format as valid JSON matching this schema: {{ ctx.output_format }}\n  \"#\n}\n\nfunction ConvertToBasicQuiz(question: string, answer: string) -> BasicQuiz {\n  client GLM4Plus\n  prompt #\"\n    {{_.role(\"user\")}}\n    Convert the following question and answer into a simple multiple choice quiz (BasicQuiz type):\n    \n    Question:\n    {{ question }}\n    \n    Answer:\n    {{ answer }}\n    \n    Requirements:\n    - Specify type as \"single\" or \"multiple\" based on answer format\n    - Format as valid JSON matching this schema: {{ ctx.output_format }}\n    - Return only the JSON object, nothing else\n    - 答案必须是选项对应的大写字母标号\n  \"#\n}\n\nclass SplitText {\n  questions string\n  answers string\n}\n\nfunction MatchQuestionsAnswers(input: SplitText) -> QuestionAnswerSlice[] {\n  client QiniuDeepseekV3\n  prompt #\"\n    {{_.role(\"user\")}}\n    Match the following questions and answers using the split point markers:\n    \n    Questions (with split markers):\n    {{ input.questions }}\n    \n    Answers (with split markers):\n    {{ input.answers }}\n    \n    Return a JSON array where each element is an object with:\n    - question_range: [start_index, end_index] of the question\n    - answer: The correct option letter(s) (A/B/C/D/E) for this question\n      - For single-choice questions: \"A\", \"B\", etc. (one letter)\n      - For multiple-choice questions: \"AB\", \"ACD\", etc. (any combination of letters)\n      - Ensure all letters are uppercase and in alphabetical order (e.g. \"ABD\" not \"BAD\")\n    \n    Match questions to answers by their position in the split points arrays.\n    Convert answer text to corresponding option letters.\n    Only return the array, nothing else.\n    Only return complete quiz that question and answer both existed.\n    Must ensure content of question/option/answer same with input text.\n  \"#\n}\n\ntest sample_quiz {\n  functions [ConvertToA1]\n  args {\n    question \"What is the capital of France?\"\n    answer \"Paris\"\n  }\n}",
  "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client GLM4Plus // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    {{_.role(\"user\")}}\n\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}